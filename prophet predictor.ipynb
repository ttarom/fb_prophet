{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-18474fa5f6a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from fbprophet import Prophet\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from holidays.holiday_base import HolidayBase\n",
    "import holidays\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "import itertools\n",
    "from dask.distributed import Client\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(user='',\n",
    "                                  password='',\n",
    "                                  host=\"\",\n",
    "                                  port=\"\",\n",
    "                                  database=\"\")\n",
    "    cursor = connection.cursor()\n",
    "    execute = \"\"\"\n",
    "    WITH CTE AS\n",
    "     (\n",
    "         SELECT s.sku,\n",
    "                date,\n",
    "                new_category,\n",
    "                quantity_total,\n",
    "                (quantity_il_web + quantity_il_store) AS quantity_il,\n",
    "                (quantity_us_web + quantity_us_store) AS quantity_us\n",
    "         FROM sales s\n",
    "                  LEFT JOIN\n",
    "              (\n",
    "                  SELECT DISTINCT sku, new_category\n",
    "                  FROM products\n",
    "              ) p\n",
    "              ON p.sku = s.sku\n",
    "         WHERE date >= '2019-01-01'\n",
    "         AND new_category IS NOT NULL\n",
    "     )\n",
    "\n",
    "SELECT date,\n",
    "   new_category,\n",
    "   SUM(quantity_total) AS quantity_total,\n",
    "   SUM(quantity_il) AS quantity_il,\n",
    "   SUM(quantity_us) AS quantity_us\n",
    "FROM CTE\n",
    "GROUP BY 1,2\n",
    "    \"\"\"\n",
    "    cursor.execute(execute)\n",
    "    connection.commit()\n",
    "    output = cursor.fetchall()\n",
    "    output = pd.DataFrame(output).rename(\n",
    "        columns={0: 'date', 1: 'new_category', 2: 'quantity_total', 3: 'quantity_il', 4: 'quantity_us'})\n",
    "    print(\"getting the latest back fill order\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Failed inserting record into table {}\".format(error))\n",
    "\n",
    "finally:\n",
    "    # closing database connection.\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "df_source = output\n",
    "output = output[output['new_category'] == 'ADK']\n",
    "output = output[['date','quantity_il']]\n",
    "output['date'] = [d.strftime('%Y-%m-%d') for d in output['date']]\n",
    "output = output.rename(columns={'date': 'ds','quantity_il': 'y'})\n",
    "output.set_index('ds', inplace=True)\n",
    "output['ds'] = output.index\n",
    "output = output[['ds','y']]\n",
    "#output['y'] += 1\n",
    "output_s = output\n",
    "print(output.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ds           holiday\n",
      "0     2010-02-26       Purim - Eve\n",
      "1     2010-02-27             Purim\n",
      "2     2010-02-28     Shushan Purim\n",
      "3     2010-03-29  Passover I - Eve\n",
      "4     2010-03-30        Passover I\n",
      "...          ...               ...\n",
      "3879  2109-12-21          Hanukkah\n",
      "3880  2109-12-22          Hanukkah\n",
      "3881  2109-12-23          Hanukkah\n",
      "3882  2109-12-24          Hanukkah\n",
      "3883  2109-12-25          Hanukkah\n",
      "\n",
      "[3884 rows x 2 columns]\n",
      "              ds                     holiday\n",
      "0     2010-01-01              New Year's Day\n",
      "1     2010-01-18  Martin Luther King Jr. Day\n",
      "2     2010-02-15       Washington's Birthday\n",
      "3     2010-05-31                Memorial Day\n",
      "4     2010-07-04            Independence Day\n",
      "...          ...                         ...\n",
      "1112  2109-09-02                   Labor Day\n",
      "1113  2109-10-14                Columbus Day\n",
      "1114  2109-11-11                Veterans Day\n",
      "1115  2109-11-28                Thanksgiving\n",
      "1116  2109-12-25               Christmas Day\n",
      "\n",
      "[1117 rows x 2 columns]\n",
      "              ds                     holiday\n",
      "0     2010-01-01              New Year's Day\n",
      "1     2010-01-18  Martin Luther King Jr. Day\n",
      "2     2010-02-15       Washington's Birthday\n",
      "3     2010-05-31                Memorial Day\n",
      "4     2010-07-04            Independence Day\n",
      "...          ...                         ...\n",
      "4996  2109-12-21                    Hanukkah\n",
      "4997  2109-12-22                    Hanukkah\n",
      "4998  2109-12-23                    Hanukkah\n",
      "4999  2109-12-24                    Hanukkah\n",
      "5000  2109-12-25                    Hanukkah\n",
      "\n",
      "[5001 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "year = 2010\n",
    "holiday_il = []\n",
    "holiday_us = []\n",
    "for date, name in sorted(holidays.IL(years=range(year, year + 100, 1)).items()):\n",
    "    holiday_il.append([date, name])\n",
    "holiday_il = pd.DataFrame(holiday_il).rename(columns={0: 'ds', 1: 'holiday'})\n",
    "print(holiday_il)\n",
    "\n",
    "for date, name in sorted(holidays.US(years=range(year, year + 100, 1)).items()):\n",
    "    holiday_us.append([date, name])\n",
    "holiday_us = pd.DataFrame(holiday_us).rename(columns={0: 'ds', 1: 'holiday'})\n",
    "print(holiday_us)\n",
    "\n",
    "holidays_all = pd.concat([holiday_us, holiday_il], ignore_index=True)\n",
    "print(holidays_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ds       holiday\n",
      "0     2010-11-15  Black Friday\n",
      "1     2010-11-16  Black Friday\n",
      "2     2010-11-17  Black Friday\n",
      "3     2010-11-18  Black Friday\n",
      "4     2010-11-19  Black Friday\n",
      "...          ...           ...\n",
      "3095  2109-12-11  Black Friday\n",
      "3096  2109-12-12  Black Friday\n",
      "3097  2109-12-13  Black Friday\n",
      "3098  2109-12-14  Black Friday\n",
      "3099  2109-12-15  Black Friday\n",
      "\n",
      "[3100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "black_friday = []\n",
    "year = 2010\n",
    "for year in range(year, year + 100, 1):\n",
    "    black_friday.append(pd.date_range(start=('%s'+\"-11-15\") % (year),end=('%s'+\"-12-15\") % (year)))\n",
    "flat_list = []\n",
    "for sublist in black_friday:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "\n",
    "black_friday = pd.DataFrame(flat_list).rename(columns={0: 'ds'})\n",
    "black_friday['ds'] = black_friday['ds'].dt.date\n",
    "black_friday['holiday'] = 'Black Friday'\n",
    "print(black_friday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ds      holiday\n",
      "0     2010-07-15  Summer sale\n",
      "1     2010-07-16  Summer sale\n",
      "2     2010-07-17  Summer sale\n",
      "3     2010-07-18  Summer sale\n",
      "4     2010-07-19  Summer sale\n",
      "...          ...          ...\n",
      "1695  2109-07-27  Summer sale\n",
      "1696  2109-07-28  Summer sale\n",
      "1697  2109-07-29  Summer sale\n",
      "1698  2109-07-30  Summer sale\n",
      "1699  2109-07-31  Summer sale\n",
      "\n",
      "[1700 rows x 2 columns]\n",
      "              ds      holiday\n",
      "0     2010-01-15  Winter sale\n",
      "1     2010-01-16  Winter sale\n",
      "2     2010-01-17  Winter sale\n",
      "3     2010-01-18  Winter sale\n",
      "4     2010-01-19  Winter sale\n",
      "...          ...          ...\n",
      "1695  2109-01-27  Winter sale\n",
      "1696  2109-01-28  Winter sale\n",
      "1697  2109-01-29  Winter sale\n",
      "1698  2109-01-30  Winter sale\n",
      "1699  2109-01-31  Winter sale\n",
      "\n",
      "[1700 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Summer_sale = []\n",
    "Winter_sale = []\n",
    "year = 2010\n",
    "for year in range(year, year + 100, 1):\n",
    "    Winter_sale.append(pd.date_range(start=('%s'+\"-01-15\") % (year),end=('%s'+\"-01-31\") % (year)))\n",
    "    Summer_sale.append(pd.date_range(start=('%s'+\"-07-15\") % (year),end=('%s'+\"-07-31\") % (year)))\n",
    "\n",
    "Summer_sale_flat = []\n",
    "Winter_sale_flat = []\n",
    "\n",
    "for sublist1 in Winter_sale:\n",
    "    for item in sublist1:\n",
    "        Winter_sale_flat.append(item)\n",
    "        \n",
    "for sublist2 in Summer_sale:\n",
    "    for item in sublist2:\n",
    "        Summer_sale_flat.append(item)\n",
    "        \n",
    "        \n",
    "\n",
    "Summer_sale = pd.DataFrame(Summer_sale_flat).rename(columns={0: 'ds'})\n",
    "Summer_sale['ds'] = Summer_sale['ds'].dt.date\n",
    "Summer_sale['holiday'] = 'Summer sale'\n",
    "print(Summer_sale)\n",
    "\n",
    "Winter_sale = pd.DataFrame(Winter_sale_flat).rename(columns={0: 'ds'})\n",
    "Winter_sale['ds'] = Winter_sale['ds'].dt.date\n",
    "Winter_sale['holiday'] = 'Winter sale'\n",
    "print(Winter_sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ds      holiday\n",
      "0     2010-01-15  Winter sale\n",
      "1     2010-01-16  Winter sale\n",
      "2     2010-01-17  Winter sale\n",
      "3     2010-01-18  Winter sale\n",
      "4     2010-01-19  Winter sale\n",
      "...          ...          ...\n",
      "3879  2109-12-21     Hanukkah\n",
      "3880  2109-12-22     Hanukkah\n",
      "3881  2109-12-23     Hanukkah\n",
      "3882  2109-12-24     Hanukkah\n",
      "3883  2109-12-25     Hanukkah\n",
      "\n",
      "[10384 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "holiday_il = pd.concat((holiday_il,black_friday,Summer_sale,Winter_sale)).sort_values(by='ds',ascending=True)\n",
    "holiday_us = pd.concat((holiday_us,black_friday,Summer_sale,Winter_sale)).sort_values(by='ds',ascending=True)\n",
    "print(holiday_il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client()  # connect to the cluster+\n",
    "\n",
    "df = output_s\n",
    "# df_cv = cross_validation(model, initial='366 days', period='90 days', horizon='425 days',\n",
    "#                          parallel=\"processes\")\n",
    "param_grid = {  \n",
    "    'changepoint_range': [0.01,0.1],\n",
    "    'changepoint_prior_scale': [0.01,0.1],\n",
    "    'seasonality_prior_scale':[1],\n",
    "    'holidays_prior_scale':[1],\n",
    "    'yearly_seasonality': [1,5,10],\n",
    "    \n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "#     control = {}\n",
    "#     control['max_treedepth'] = 15\n",
    "#     control['adapt_delta'] = 0.99\n",
    "    m = Prophet(**params,\n",
    "            interval_width=0.95,\n",
    "            daily_seasonality=False,\n",
    "            #seasonality_mode='multiplicative',\n",
    "            holidays=holiday_il,   \n",
    "#             mcmc_samples=200,\n",
    "            ).fit(df)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, initial='366 days', period='30 days', horizon='366 days', parallel=\"processes\")\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = all_params[np.argmin(rmses)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = performance_metrics(df_cv)\n",
    "df_p.head(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_validation_metric(df_cv, metric='mape')\n",
    "df_p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "output = output_s\n",
    "client = Client()\n",
    "\n",
    "control = {}\n",
    "control['max_treedepth'] = 15\n",
    "control['adapt_delta'] = 0.99\n",
    "\n",
    "model = Prophet(\n",
    "            interval_width=0.95,\n",
    "            daily_seasonality=False,\n",
    "            holidays=holiday_il,\n",
    "            seasonality_prior_scale=1,\n",
    "            yearly_seasonality=10,\n",
    "            changepoint_prior_scale=0.01,\n",
    "            changepoint_range=0.1,\n",
    "            holidays_prior_scale=1,\n",
    "            seasonality_mode='multiplicative',\n",
    "            #mcmc_samples=200\n",
    "            )\n",
    "model.fit(output)\n",
    "\n",
    "forecast = model.make_future_dataframe(periods=365, freq='d',  include_history=True)\n",
    "forecast = model.predict(forecast)\n",
    "\n",
    "# Plot the forecast with the actuals\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=output_s['ds'], y=output_s['y'], name='Actual'))\n",
    "fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], name='Predicted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = [] \n",
    "\n",
    "df_cv = cross_validation(model, initial='366 days', period='31 days', horizon='366 days', parallel=\"processes\")\n",
    "df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "mape.append(df_p['mape'].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the components of the model\n",
    "fig = model.plot_components(forecast)\n",
    "plot_cross_validation_metric(df_cv, metric='mape')\n",
    "df_p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_yhat = forecast['yhat'][(forecast['ds']>='2021-01-01') & (forecast['ds']<'2021-03-01')].sum()\n",
    "print('Forecast sum is:', sum_yhat)\n",
    "sum_y = output_s['y'][731:790].sum()\n",
    "print('Actual sum is:', sum_y)\n",
    "gap = sum_yhat-sum_y\n",
    "print('gap predict to actual: ',gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = forecast[['ds','yhat']]\n",
    "# df = df.rename(columns={'ds':'date', 'yhat':'qty_pred'})\n",
    "# print(df)\n",
    "# try:\n",
    "#     connection = psycopg2.connect(user='',\n",
    "#                                   password='',\n",
    "#                                   host=\"\",\n",
    "#                                   port=\"\",\n",
    "#                                   database=\"\")\n",
    "\n",
    "#     records_to_insert = list(df.itertuples(index=False, name=None))\n",
    "#     cursor = connection.cursor()\n",
    "#     args_strings = ','.join(cursor.mogrify(\"(%s,%s,%s,%s)\", x).decode('utf-8') for x in records_to_insert)\n",
    "#     sql_insert_query = \"INSERT INTO prophet VALUES \" + args_strings\n",
    "#     cursor.execute(sql_insert_query)\n",
    "#     connection.commit()\n",
    "#     print(cursor.rowcount, \"Record inserted successfully into table\")\n",
    "\n",
    "# except (Exception, psycopg2.Error) as error:\n",
    "#     print(\"Failed inserting record into table {}\".format(error))\n",
    "\n",
    "# finally:\n",
    "#     # closing database connection.\n",
    "#     if connection:\n",
    "#         cursor.close()\n",
    "#         connection.close()\n",
    "#         print(\"PostgreSQL connection is closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
